{"cells":[{"metadata":{},"cell_type":"markdown","source":"The aim of the project is to identify the accuracy of R2 score for different tree-based models, covering:\n- Decision Tree\n- Random Forest\n- XG Boost\n- LightGBM\n\nMeanwhile, the cross validation will be also adopted for model evaluation\n\nThe use of data cleaning is firstly adopted for the input of regression model. \n\n"},{"metadata":{"_uuid":"c0f9ab84-cf22-4af6-8ea0-d068c041c572","_cell_guid":"dd3dd1ee-a70f-48c4-9c87-7af2596080de","trusted":true},"cell_type":"code","source":"import re\nimport sys\nimport time\nimport datetime\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\n\nfrom mpl_toolkits.mplot3d import Axes3D\nimport matplotlib as mpl\nimport numpy as np\nimport seaborn as sns\nfrom sklearn import preprocessing\nfrom sklearn.decomposition import PCA\nfrom sklearn.linear_model import LinearRegression, LogisticRegression\nfrom sklearn import linear_model\nimport statsmodels.api as sm\nimport sklearn.model_selection as ms\nfrom sklearn import neighbors\nfrom sklearn import tree\nfrom sklearn.cluster import KMeans\nfrom sklearn.neighbors import KDTree\nfrom sklearn import svm\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import train_test_split,cross_val_score, ShuffleSplit\nfrom sklearn.model_selection import StratifiedKFold,KFold,GridSearchCV,RandomizedSearchCV\nfrom sklearn import metrics\nfrom sklearn.metrics import r2_score,mean_squared_error,confusion_matrix\n\nfrom xgboost import XGBRegressor \nfrom lightgbm import LGBMRegressor \n\nfrom tensorflow import keras\nfrom keras import backend as K\nfrom keras.models import Sequential\nfrom keras.layers import Dense\n\ndatabase = pd.read_csv(r\"../input/google-play-store-apps/googleplaystore.csv\")# store wine type as an attribute\n\n\n\n#############################################################  \n######Data Cleaning\n\ni = database[database['Category'] == '1.9'].index\ndatabase.loc[i]\ndatabase = database.drop(i)\n\ndatabase = database[pd.notnull(database['Last Updated'])]\ndatabase = database[pd.notnull(database['Content Rating'])]\n\n\nCategoryList = database['Category'].unique().tolist() \nCategoryList = ['cat_' + word for word in CategoryList]\ndatabase = pd.concat([database, pd.get_dummies(database['Category'], prefix='cat')], axis=1)\n\n\ndatabase['Rating'] = database['Rating'].fillna(database['Rating'].median())\ndatabase['Installs'] = database['Installs'].apply(lambda x : x.strip('+').replace(',', ''))\ndatabase['Type'] = pd.get_dummies(database['Type'])\ndatabase['Price'] = database['Price'].apply(lambda x : x.strip('$'))\ndatabase['Last Updated'] = database['Last Updated'].apply(lambda x : time.mktime(datetime.datetime.strptime(x, '%B %d, %Y').timetuple()))\n\n\n#######################################################\n###### Encoding\n\nLE = preprocessing.LabelEncoder()\ndatabase['App'] = LE.fit_transform(database['App'])\ndatabase['Genres'] = LE.fit_transform(database['Genres'])\ndatabase['Content Rating'] = LE.fit_transform(database['Content Rating'])\n\n\n########################################################\n###### Size\n\n\nk_indices = database['Size'].loc[database['Size'].str.contains('k')].index.tolist()\nconverter = pd.DataFrame(database.loc[k_indices, 'Size'].apply(lambda x: x.strip('k')).astype(float).apply(lambda x: x / 1024).apply(lambda x: round(x, 3)).astype(str))\ndatabase.loc[k_indices,'Size'] = converter\n\ndatabase['Size'] = database['Size'].apply(lambda x: x.strip('M'))\ndatabase[database['Size'] == 'Varies with device'] = 0\ndatabase['Size'] = database['Size'].astype(float)\n","execution_count":11,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"After the shuffled the database, the features of the dataset are selected and listed below:\n\n- App \n- Reviews\n- Size\n- Installs\n- Type \n- Price\n- Content Rating \n- Genres, \n- Last Updated\n\nThe output I want to evaluate is Rating "},{"metadata":{"trusted":true},"cell_type":"code","source":"########################################################\n###### Feature Selection\n\nshuffled_database = database.reindex(np.random.permutation(database.index))\n\n\nfeatures = ['App', 'Reviews', 'Size', 'Installs', 'Type', 'Price', 'Content Rating', 'Genres', 'Last Updated']\nshuffled_database[features]=shuffled_database[features].astype(float)\nX = shuffled_database[features]\ny = shuffled_database['Rating']\n\n\n#######################################################\n##### Train Test Split\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state=10)\n","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"###################################################################\n### DecisionTreeRegressor\n\nDT_Regression = tree.DecisionTreeRegressor(criterion='mae', max_depth=5, min_samples_leaf=5, random_state=42)\nDT_Regression.fit(X_train,y_train)\ny_DT_pred=DT_Regression.predict(X_test)\nDT_Regression_score=DT_Regression.score(X_test,y_test)\n\n\nprint(\"with train test split_DecisionTreeRegression\", DT_Regression_score)\nprint('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_DT_pred))\nprint('Mean Squared Error:', metrics.mean_squared_error(y_test, y_DT_pred))\nprint('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_DT_pred)), '\\n')","execution_count":13,"outputs":[{"output_type":"stream","text":"with train test split_DecisionTreeRegression 0.9204473450232281\nMean Absolute Error: 0.25510455104551044\nMean Squared Error: 0.2044218942189422\nRoot Mean Squared Error: 0.45213039515049436 \n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"###################################################################\n### RandomForestRegressor\n\nRF_Regression= RandomForestRegressor(random_state=20)\nRF_Regression.fit(X_train,y_train)\ny_RF_pred=RF_Regression.predict(X_test)\nRF_Regression_score=RF_Regression.score(X_test,y_test)\n\nprint(\"with train test split_RandomForestRegression\", RF_Regression_score)\nprint('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_RF_pred))\nprint('Mean Squared Error:', metrics.mean_squared_error(y_test, y_RF_pred))\nprint('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_RF_pred)), '\\n')\n","execution_count":14,"outputs":[{"output_type":"stream","text":"with train test split_RandomForestRegression 0.9300828559826425\nMean Absolute Error: 0.2539384993849937\nMean Squared Error: 0.17966207441574408\nRoot Mean Squared Error: 0.42386563250132003 \n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"###################################################################\n### XGBRegressor\n\n\nXGB_Regression= XGBRegressor(random_state=20)\nXGB_Regression.fit(X_train,y_train)\ny_XBG_pred=XGB_Regression.predict(X_test)\nRF_Regression_score=XGB_Regression.score(X_test,y_test)\n\nprint(\"with train test split_XGBRegression\", RF_Regression_score)\nprint('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_XBG_pred))\nprint('Mean Squared Error:', metrics.mean_squared_error(y_test, y_XBG_pred))\nprint('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_XBG_pred)), '\\n')\n","execution_count":15,"outputs":[{"output_type":"stream","text":"with train test split_XGBRegression 0.9245566313261124\nMean Absolute Error: 0.26835015173107934\nMean Squared Error: 0.19386249692203422\nRoot Mean Squared Error: 0.4402981909138785 \n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"###################################################################\n### LightGBM\n\n\nLGBM_Regression = LGBMRegressor(random_state=20)\nLGBM_Regression.fit(X_train,y_train)\ny_LGBM_pred=LGBM_Regression.predict(X_test)\nLGBM_Regression_socre=LGBM_Regression.score(X_test,y_test)\n\nprint(\"with train test split_LGBM_Regression\", LGBM_Regression_socre)\nprint('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_LGBM_pred))\nprint('Mean Squared Error:', metrics.mean_squared_error(y_test, y_LGBM_pred))\nprint('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_LGBM_pred)), '\\n')","execution_count":16,"outputs":[{"output_type":"stream","text":"with train test split_LGBM_Regression 0.9302825505053431\nMean Absolute Error: 0.25793118637779705\nMean Squared Error: 0.17914893085557576\nRoot Mean Squared Error: 0.4232598857151192 \n\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"The cross validation is performed in order to evaluate the model with multiple train-test splits. But it is more time consuming compared to train test split"},{"metadata":{"trusted":true},"cell_type":"code","source":"####################################################\n## Result with Cross Validation Score and Prediction\n\nscore_CV_XGB_Regression = cross_val_score(XGB_Regression,X,y,cv=5 ,scoring='r2')\nprint(\"with CV XGB_Regression\", score_CV_XGB_Regression.mean())","execution_count":17,"outputs":[{"output_type":"stream","text":"with CV XGB_Regression 0.9255910217946182\n","name":"stdout"}]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}